{
  "models": [
    {
      "id": "llama32-1b-q6k",
      "name": "Llama 3.2 1B Q6_K",
      "repo_id": "bartowski/Llama-3.2-1B-Instruct-GGUF",
      "local_path": "bartowski/Llama-3.2-1B-Instruct-GGUF",
      "file_patterns": [
        "Llama-3.2-1B-Instruct-Q6_K.gguf"
      ],
      "size_bytes": 0,
      "downloaded_at": null,
      "is_default": true,
      "description": "Meta Llama 3.2 1B Instruct, Q6_K quantization - Very high quality, near perfect, recommended",
      "quantization": "Q6_K",
      "context_window": 4096,
      "parameters": "1B",
      "temperature": 0.3,
      "top_k": null,
      "top_p": 0.9,
      "min_p": null,
      "max_tokens": 512,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "stop": ["\n"],
      "stream": false,
      "timeout": 30,
      "retries": 3,
      "n_gpu_layers": 33,
      "n_threads": 8,
      "use_mmap": true,
      "use_mlock": true,
      "ngl": 33,
      "main_gpu": 0,
      "tensor_split": null
    },
    {
      "id": "gemma-3n-E4B-it-GGUF",
      "name": "Gemma 3n Q6_K_L",
      "repo_id": "unsloth/gemma-3n-E4B-it-GGUF",
      "local_path": "unsloth/gemma-3n-E4B-it-GGUF",
      "file_patterns": [
        "gemma-3n-E4B-it-Q6_K.gguf"
      ],
      "size_bytes": 0,
      "downloaded_at": "",
      "is_default": false,
      "description": "multimodal", 
      "quantization": "Q6_K",
      "context_window": 32768,
      "parameters": "4B",
      "temperature": 1.0,
      "top_k": 64,
      "top_p": 0.95,
      "min_p": 0.0,
      "max_tokens": 512,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "stop": ["\n"],
      "stream": false,
      "timeout": 30,
      "retries": 3,
      "n_gpu_layers": 33,
      "n_threads": 8,
      "use_mmap": true,
      "use_mlock": true,
      "ngl": 33,
      "main_gpu": 0,
      "tensor_split": null
    },
    {
      "id": "gemma-3-4b-it-text-only-tensorblock",
      "name": "gemma-3-4b-it text-only Q5_K_M",
      "repo_id": "tensorblock/gemma-3-4b-it-text-only-GGUF",
      "local_path": "tensorblock/gemma-3-4b-it-text-only-GGUF",
      "file_patterns": [
        "gemma-3-4b-it-text-only-Q5_K_M.gguf"
      ],
      "size_bytes": 0,
      "downloaded_at": "",
      "is_default": false,
      "description": "text-only",
      "quantization": "Q5_K_M",
      "context_window": 32768,
      "parameters": "4B",
      "temperature": 1.0,
      "top_k": 64,
      "top_p": 0.95,
      "min_p": 0.0,
      "max_tokens": 512,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "stop": ["\n"],
      "stream": false,
      "timeout": 30,
      "retries": 3,
      "n_gpu_layers": 33,
      "n_threads": 8,
      "use_mmap": true,
      "use_mlock": true,
      "ngl": 33,
      "main_gpu": 0,
      "tensor_split": null
    },
    {
      "id": "gemma-3-270m-it-GGUF",
      "name": "gemma-3-270m Q8_0",
      "repo_id": "ggml-org/gemma-3-270m-GGUF",
      "local_path": "ggml-org/gemma-3-270m-GGUF",
      "file_patterns": [
        "gemma-3-270m-Q8_0.gguf"
      ],
      "size_bytes": 0,
      "downloaded_at": "",
      "is_default": false,
      "description": "text-only",
      "quantization": "Q8_0",
      "context_window": 32768,
      "parameters": "270M",
      "temperature": 1.0,
      "top_k": 64,
      "top_p": 0.95,
      "min_p": 0.0,
      "max_tokens": 512,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "stop": ["\n"],
      "stream": false,
      "timeout": 30,
      "retries": 3,
      "n_gpu_layers": 33,
      "n_threads": 8,
      "use_mmap": true,
      "use_mlock": true,
      "ngl": 33,
      "main_gpu": 0,
      "tensor_split": null
    },
    {
      "id": "SmolLM3-3B-GGUF",
      "name": "SmolLM3 3B Q4_K_M",
      "repo_id": "ggml-org/SmolLM3-3B-GGUF",
      "local_path": "ggml-org/SmolLM3-3B-GGUF",
      "file_patterns": [
        "SmolLM3-Q4_K_M.gguf"
      ],
      "size_bytes": 0,
      "downloaded_at": "",
      "is_default": false,
      "description": "text-only",
      "quantization": "Q4_K_M",
      "context_window": 32768,
      "parameters": "3B",
      "temperature": 1.0,
      "top_k": 64,
      "top_p": 0.95,
      "min_p": 0.0,
      "max_tokens": 512,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "stop": ["\n"],
      "stream": false,
      "timeout": 30,
      "retries": 3,
      "n_gpu_layers": 33,
      "n_threads": 8,
      "use_mmap": true,
      "use_mlock": true,
      "ngl": 33,
      "main_gpu": 0,
      "tensor_split": null
    }
  ],
  "last_updated": "2025-10-29T05:30:00.000000"
}