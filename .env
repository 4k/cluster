# AI Assistant Configuration

# Application Settings
APP_NAME=AI_Assistant
APP_VERSION=1.0.0
DEBUG=false
LOG_LEVEL=INFO

# LLM Provider Settings
LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Local LLM Settings (for llama.cpp or similar)
LOCAL_MODEL_PATH=./models
MODEL_NAME=llama-2-7b-chat
CONTEXT_SIZE=2048
GPU_LAYERS=0

# Audio Settings
ENABLE_AUDIO=true
SAMPLE_RATE=16000
CHANNELS=1
CHUNK_SIZE=1024

# Speech-to-Text (STT) Settings
STT_PROVIDER=whisper
WHISPER_MODEL=base
VAD_ENABLED=true
WAKE_WORD=hey_assistant

# Text-to-Speech (TTS) Settings
TTS_PROVIDER=piper
TTS_MODEL=en_US-lessac-medium
VOICE_SPEED=1.0

# Display Settings
ENABLE_DISPLAY=true
DISPLAY_MODE=terminal
DISPLAY_WIDTH=800
DISPLAY_HEIGHT=600

# Animation Settings
ENABLE_ANIMATION=true
ANIMATION_FPS=30

# Memory Settings
ENABLE_MEMORY=true
MEMORY_SIZE=10
CONVERSATION_HISTORY_PATH=./logs/chats

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# Device Settings
DEVICE=cpu
# Options: cpu, cuda, mps
